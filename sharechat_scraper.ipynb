{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "from os.path import basename\n",
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "import tzlocal\n",
    "from IPython.display import Image, HTML\n",
    "import time\n",
    "from time import sleep\n",
    "from random import uniform\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API scraper\n",
    "\n",
    "# Parameters for API scraper - update as required\n",
    "\n",
    "USER_ID = 341972726 # Sharechat user id\n",
    "\n",
    "PASSCODE = \"dcdb36a4dc99d6a39547\" # inspect page > network > bucketFeed or requestType81 > headers > request payload > passcode\n",
    "\n",
    "# Tag specific params from sharechat.com/tag > inspect ... > request payload \n",
    "tag_dict = {\n",
    "    \"trending/Hindi\": {\n",
    "        \"tag_body\": {\n",
    "            \"bn\":\"broker3\",\"userId\": USER_ID,\"passCode\": PASSCODE,\n",
    "                        \"client\":\"web\",\"message\":{\n",
    "                            \"r\":\"web\", \"f\": 0, \"p\":\"f\"}},\n",
    "        \"api_url\" : \"https://restapi1.sharechat.com/requestType81\"},\n",
    "    \"topic/whatsapp-hindi-238\": {\n",
    "        \"tag_body\": {\n",
    "            \"bn\":\"broker3\",\"userId\": USER_ID,\"passCode\": PASSCODE,\n",
    "                        \"client\":\"web\",\"message\":{\n",
    "                            \"b\":238,\"allowOffline\":True}},\n",
    "        \"api_url\": \"https://restapi1.sharechat.com/bucketFeed\"},\n",
    "    \"topic/news-hindi-125\": {\n",
    "        \"tag_body\": {\n",
    "            \"bn\":\"broker3\",\"userId\": USER_ID,\"passCode\": PASSCODE,\n",
    "                        \"client\":\"web\",\"message\":{\n",
    "                            \"b\":238,\"allowOffline\":True}},\n",
    "        \"api_url\": \"https://restapi1.sharechat.com/bucketFeed\"}}\n",
    "\n",
    "d = os.getcwd() # Download destination\n",
    "\n",
    "# Set timezone\n",
    "local_timezone = tzlocal.get_localzone()\n",
    "\n",
    "# Tags to scrape\n",
    "t = [\"topic/news-hindi-125\", \"topic/whatsapp-hindi-238\", \"trending/Hindi\"]\n",
    "\n",
    "# Number of pages to scrape\n",
    "n = 10\n",
    "\n",
    "# Helper functions for API scraper \n",
    "\n",
    "# Scrapes data from specified tags\n",
    "def get_data(tags, pages):\n",
    "    # Create empty dataframe to collect scraped data\n",
    "    df = pd.DataFrame(columns = [\"link\", \"timestamp\", \"lang\", \n",
    "                                   \"media_type\", \"tag\", \"thumbnail\"])\n",
    "    print(\"Scraping data from Sharechat ...\")\n",
    "    for _ in range(pages):\n",
    "        # Scrape data from each tag\n",
    "        for tag in tags: \n",
    "            # Get tag specific API access params\n",
    "            url = tag_dict[tag][\"api_url\"]\n",
    "            body = tag_dict[tag][\"tag_body\"]\n",
    "            headers = {\"content-type\": \"application/json\", \n",
    "                           \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36\"} \n",
    "            \n",
    "            response = requests.post(url, json=body, headers=headers)\n",
    "            response_dict = json.loads(response.text)\n",
    "            \n",
    "            link, timestamp, lang, media_type = get_payload_data(response_dict)\n",
    "            tag_data = pd.DataFrame(np.column_stack([link, timestamp, lang, media_type]), \n",
    "                            columns = [\"link\", \"timestamp\", \"lang\", \"media_type\"])\n",
    "            \n",
    "            # Add tag column \n",
    "            tag_data[\"tag\"] = tag\n",
    "            # Add thumbnail column\n",
    "            tag_data[\"thumbnail\"] = tag_data[\"link\"]\n",
    "            # Add tag data \n",
    "            df = df.append(tag_data)  \n",
    "            time.sleep(uniform(5, 10)) # random delay after each API request\n",
    "    df[\"timestamp\"] = df[\"timestamp\"].apply(lambda x: datetime.fromtimestamp(int(x), local_timezone).strftime(\"%d-%m-%Y, %H:%M:%S\"))\n",
    "    df.drop_duplicates(inplace = True)\n",
    "    return df\n",
    "\n",
    "# Gets image/video data from scraped payload \n",
    "def get_payload_data(payload_dict):\n",
    "    link = []\n",
    "    timestamp = []\n",
    "    lang = []\n",
    "    media_type = []\n",
    "    for i in payload_dict[\"payload\"][\"d\"]:\n",
    "        if (i[\"t\"] == \"image\") | (i[\"t\"] == \"video\"):\n",
    "            timestamp.append(i[\"o\"])\n",
    "            lang.append(i[\"m\"])\n",
    "            media_type.append(i[\"t\"])\n",
    "            if i[\"t\"] == \"image\":\n",
    "                link.append(i[\"g\"])\n",
    "            else:\n",
    "                link.append(i[\"v\"])\n",
    "        else:\n",
    "            pass # skip other content formats\n",
    "    return link, timestamp, lang, media_type\n",
    "\n",
    "#Converts links to thumbnails in html\n",
    "def convert_links_to_thumbnails(df):   \n",
    "    def path_to_image_html(path):\n",
    "        return '<img src=\"'+ path + '\"width=\"200\" >' \n",
    "    image_df = df[df[\"media_type\"] == \"image\"]\n",
    "    pd.set_option('display.max_colwidth', -1)\n",
    "    data_html = HTML(image_df.to_html(escape=False ,formatters=dict(thumbnail=path_to_image_html))) \n",
    "    return data_html\n",
    "\n",
    "# Saves data in csv and html formats\n",
    "def save_data(df, html):\n",
    "    with open(\"sharechat_data_preview.html\", \"w\") as f:\n",
    "        f.write(html.data)\n",
    "    df.drop(\"thumbnail\", axis = 1, inplace = True)\n",
    "    df.to_csv(\"sharechat_data.csv\")\n",
    "    \n",
    "# Define API scraper \n",
    "def sharechat_scraper(tags, destination, pages):\n",
    "    start_time = time.time()\n",
    "    # Scrape data from each tag\n",
    "    sharechat_df = get_data(tags, n)\n",
    "    # Generate html file with image thumbnails\n",
    "    sharechat_data_html = convert_links_to_thumbnails(sharechat_df)\n",
    "    # Save data \n",
    "    save_data(sharechat_df, sharechat_data_html)\n",
    "    print(\"{} posts scraped\".format(len(sharechat_df)))\n",
    "    print(\"Data saved to\", destination)\n",
    "    print(\"Time taken: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run API scraper\n",
    "sharechat_scraper(t, d, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beautiful Soup scraper\n",
    "\n",
    "# Define scraper arguments\n",
    "t = [\"topic/news-hindi-125\", \"topic/whatsapp-hindi-238\", \"trending/Hindi\"] # tags to scrape\n",
    "d = os.getcwd() # download destination\n",
    "\n",
    "# Define helper functions for Beautiful Soup scraper\n",
    "\n",
    "# Scrapes data from specified tags\n",
    "def get_data(tags):\n",
    "    # Create empty dataframe to collect scraped data\n",
    "    data = pd.DataFrame(columns = [\"img_link\", \"timestamp\", \"tag\", \"thumbnail\"])\n",
    "    # Scrape data from each tag\n",
    "    for tag in tags: \n",
    "        print(\"Scraping recent images from https://sharechat.com/\"+tag+\" ...\")\n",
    "        soup = get_parsed_page(tag) \n",
    "        img_links, timestamps = get_images_with_timestamps(soup)  \n",
    "        # Save tag data as dataframe\n",
    "        tag_data = pd.DataFrame(np.column_stack([img_links, timestamps]), \n",
    "                            columns = [\"img_link\", \"timestamp\"])\n",
    "        # Add tag column \n",
    "        tag_data[\"tag\"] = tag\n",
    "        # Add thumbnail column\n",
    "        tag_data[\"thumbnail\"] = tag_data[\"img_link\"]   \n",
    "        # Add tag data \n",
    "        data = data.append(tag_data)\n",
    "    return data\n",
    "\n",
    "# Returns parsed web page\n",
    "def get_parsed_page(tag):\n",
    "    r = requests.get(\"https://sharechat.com/\"+tag)\n",
    "    c = r.content\n",
    "    soup = BeautifulSoup(c, \"lxml\") \n",
    "    return soup\n",
    "\n",
    "# Returns images with timestamps\n",
    "def get_images_with_timestamps(soup):\n",
    "    # Initialize empty lists to hold data\n",
    "    img_links = []\n",
    "    timestamps = []\n",
    "    # Find image\n",
    "    images = soup.findAll(\"img\", {\"src\": re.compile(\".jpg\")}) \n",
    "    for image in images:\n",
    "        # Add image link\n",
    "        img_links.append(image[\"src\"]) \n",
    "        # Find timestamp\n",
    "        unix_ts = re.findall(\"\\d{13}\", image[\"src\"]) \n",
    "        if (len(unix_ts) > 0): # If link contains timestamp\n",
    "        # Reformat and save timestamp\n",
    "            local_time = datetime.fromtimestamp(int(\"\".join(unix_ts))/1000, local_timezone).strftime(\"%d:%m:%Y, %H:%M:%S\")\n",
    "            timestamps.append(local_time) \n",
    "        else:\n",
    "            timestamps.append(None)\n",
    "    return img_links, timestamps\n",
    "\n",
    "# Adds image thumbnails for quick viewing\n",
    "def convert_links_to_thumbnails(df):   \n",
    "    def path_to_image_html(path):\n",
    "        return '<img src=\"'+ path + '\"width=\"200\" >' \n",
    "    data_html = HTML(df.to_html(escape=False ,formatters=dict(thumbnail=path_to_image_html))) \n",
    "    return data_html\n",
    "\n",
    "# Saves scraped data in csv and html formats\n",
    "def save_data(df, html):\n",
    "    with open(\"sharechat_data_html.html\", \"w\") as f:\n",
    "        f.write(html.data)\n",
    "    df.drop(\"thumbnail\", axis = 1, inplace = True)\n",
    "    df.to_csv(\"sharechat_data.csv\")\n",
    "    \n",
    "# Define Beautiful Soup scraper \n",
    "def sharechat_soup_scraper(tags, destination):\n",
    "    # Scrape data from specified tags\n",
    "    sharechat_df = get_data(tags)\n",
    "    # Generate html file with image thumbnails\n",
    "    sharechat_data_html = convert_links_to_thumbnails(sharechat_df)\n",
    "    # Save data \n",
    "    save_data(sharechat_df, sharechat_data_html)\n",
    "    print(\"{} images scraped\".format(len(sharechat_df)))\n",
    "    print(\"Data saved to\", destination)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Beautiful Soup scraper\n",
    "sharechat_soup_scraper(t, d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
