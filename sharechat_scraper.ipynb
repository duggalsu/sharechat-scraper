{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "from os.path import basename\n",
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "import tzlocal\n",
    "from IPython.display import Image, HTML\n",
    "import time\n",
    "from time import sleep\n",
    "from random import uniform\n",
    "import json\n",
    "import lxml\n",
    "from lxml import etree\n",
    "import selenium\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API bucket scraper\n",
    "\n",
    "# Parameters - update as required\n",
    "\n",
    "USER_ID = os.environ(\"SHARECHAT_USER_ID\")\n",
    "\n",
    "PASSCODE = os.environ(\"SHARECHAT_PASSWORD\") # inspect page > network > bucketFeed or requestType81 > headers > request payload > passcode\n",
    "\n",
    "# Tag specific params from sharechat.com/tag > inspect ... > request payload \n",
    "bucket_dict = {\n",
    "    \"trending/Hindi\": {\n",
    "        \"bucket_body\": {\n",
    "            \"bn\":\"broker3\",\"userId\": USER_ID,\"passCode\": PASSCODE,\n",
    "                        \"client\":\"web\",\"message\":{\n",
    "                            \"r\":\"web\", \"f\": 0, \"p\":\"f\"}},\n",
    "        \"api_url\" : \"https://restapi1.sharechat.com/requestType81\"},\n",
    "    \"topic/whatsapp-hindi-238\": {\n",
    "        \"bucket_body\": {\n",
    "            \"bn\":\"broker3\",\"userId\": USER_ID,\"passCode\": PASSCODE,\n",
    "                        \"client\":\"web\",\"message\":{\n",
    "                            \"b\":238,\"allowOffline\":True}},\n",
    "        \"api_url\": \"https://restapi1.sharechat.com/bucketFeed\"},\n",
    "    \"topic/news-hindi-125\": {\n",
    "        \"bucket_body\": {\n",
    "            \"bn\":\"broker3\",\"userId\": USER_ID,\"passCode\": PASSCODE,\n",
    "                        \"client\":\"web\",\"message\":{\n",
    "                            \"b\":125,\"allowOffline\":True}},\n",
    "        \"api_url\": \"https://restapi1.sharechat.com/bucketFeed\"}}\n",
    "\n",
    "d = os.getcwd() # Download destination\n",
    "\n",
    "# Set timezone\n",
    "local_timezone = tzlocal.get_localzone()\n",
    "\n",
    "# Buckets to scrape\n",
    "b = [\"topic/news-hindi-125\", \"topic/whatsapp-hindi-238\", \"trending/Hindi\"]\n",
    "\n",
    "# Number of pages to scrape\n",
    "n = 5\n",
    "\n",
    "# Define helper functions\n",
    "\n",
    "# Scrapes data from specified tags\n",
    "def get_data(buckets, pages):\n",
    "    # Create empty dataframe to collect scraped data\n",
    "    df = pd.DataFrame(columns = [\"link\", \"timestamp\", \"lang\", \n",
    "                                   \"media_type\", \"tag\", \"thumbnail\"])\n",
    "    print(\"Scraping data from Sharechat ...\")\n",
    "    for bucket in buckets:\n",
    "        # Scrape data from each tag\n",
    "        for _ in range(pages):\n",
    "            url = bucket_dict[bucket][\"api_url\"]\n",
    "            body = bucket_dict[bucket][\"tag_body\"]\n",
    "            headers = {\"content-type\": \"application/json\", \n",
    "                           \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36\"} \n",
    "            response = requests.post(url, json=body, headers=headers)\n",
    "            response_dict = json.loads(response.text)\n",
    "            \n",
    "            link, timestamp, lang, media_type = get_payload_data(response_dict)\n",
    "            bucket_data = pd.DataFrame(np.column_stack([link, timestamp, lang, media_type]), \n",
    "                            columns = [\"link\", \"timestamp\", \"lang\", \"media_type\"])\n",
    "            \n",
    "            # Add bucket column \n",
    "            bucket_data[\"bucket\"] = bucket\n",
    "            # Add thumbnail column\n",
    "            bucket_data[\"thumbnail\"] = bucket_data[\"link\"]\n",
    "            # Add bucket data \n",
    "            df = df.append(bucket_data)  \n",
    "            time.sleep(uniform(30, 35)) # random delay after each request\n",
    "    df[\"timestamp\"] = df[\"timestamp\"].apply(lambda x: datetime.fromtimestamp(int(x), local_timezone).strftime(\"%d-%m-%Y, %H:%M:%S\"))\n",
    "    df.drop_duplicates(inplace = True)\n",
    "    return df\n",
    "\n",
    "# Gets image/video data from scraped payload \n",
    "def get_payload_data(payload_dict):\n",
    "    link = []\n",
    "    timestamp = []\n",
    "    lang = []\n",
    "    media_type = []\n",
    "    for i in payload_dict[\"payload\"][\"d\"]:\n",
    "        if (i[\"t\"] == \"image\") | (i[\"t\"] == \"video\"):\n",
    "            timestamp.append(i[\"o\"])\n",
    "            lang.append(i[\"m\"])\n",
    "            media_type.append(i[\"t\"])\n",
    "            if i[\"t\"] == \"image\":\n",
    "                link.append(i[\"g\"])\n",
    "            else:\n",
    "                link.append(i[\"v\"])\n",
    "        else:\n",
    "            pass # skip other content formats\n",
    "    return link, timestamp, lang, media_type\n",
    "\n",
    "# Converts links to thumbnails in html\n",
    "def convert_links_to_thumbnails(df):   \n",
    "    def path_to_image_html(path):\n",
    "        return '<img src=\"'+ path + '\"width=\"200\" >' \n",
    "    image_df = df[df[\"media_type\"] == \"image\"]\n",
    "    pd.set_option('display.max_colwidth', -1)\n",
    "    data_html = HTML(image_df.to_html(escape=False ,formatters=dict(thumbnail=path_to_image_html))) \n",
    "    return data_html\n",
    "\n",
    "# Saves data in csv and html formats\n",
    "def save_data(df, html):\n",
    "    with open(\"sharechat_bucket_data_preview.html\", \"w\") as f:\n",
    "        f.write(html.data)\n",
    "    df.drop(\"thumbnail\", axis = 1, inplace = True)\n",
    "    df.to_csv(\"sharechat_bucket_data.csv\")\n",
    "\n",
    "# Build API scraper\n",
    "def sharechat_bucket_scraper(buckets, destination, pages):\n",
    "    start_time = time.time()\n",
    "    # Scrape data from each bucket\n",
    "    sharechat_df = get_data(buckets, n)\n",
    "    # Generate html file with image thumbnails\n",
    "    sharechat_data_html = convert_links_to_thumbnails(sharechat_df)\n",
    "    # Save data \n",
    "    save_data(sharechat_df, sharechat_data_html)\n",
    "    print(\"{} posts scraped\".format(len(sharechat_df)))\n",
    "    print(\"Data saved to\", destination)\n",
    "    print(\"Time taken: %s seconds\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run bucket scraper\n",
    "sharechat_bucket_scraper(b, d, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API scraper for tags within bucket\n",
    "\n",
    "# Parameters for API scraper - update as required\n",
    "USER_ID = 348849803 # Sharechat user id\n",
    "PASSCODE = \"e555de8136fb06944f7f\" # inspect page > network > bucketFeed or requestType81 > headers > request payload > passcode\n",
    "PATH = os.getcwd()\n",
    "CHROMEDRIVER_PATH = os.path.join(PATH, \"chromedriver\")\n",
    "\n",
    "# Download destination - TO UPDATE\n",
    "d = \"/Users/kruttikanadig/Desktop\"\n",
    "\n",
    "# Set timezone\n",
    "local_timezone = tzlocal.get_localzone()\n",
    "\n",
    "buckets = {\"hindi_coronavirus\": \"https://sharechat.com/buckets/125?referrer=explorePage\",\n",
    "          \"hindi_news\": \"https://sharechat.com/buckets/1284?referrer=bucketViewPage\"}\n",
    "\n",
    "# Helper functions for scraper\n",
    "def get_tag_hashes(buckets): \n",
    "    tag_hashes = []\n",
    "    for bucket in buckets:\n",
    "        hashes = []\n",
    "        bucket_page = buckets[bucket]\n",
    "        driver = webdriver.Chrome(executable_path = CHROMEDRIVER_PATH)\n",
    "        driver.get(bucket_page)\n",
    "        driver.find_element_by_xpath('/html/body/div[1]/div[1]/main/div/div/div[1]').click()\n",
    "        time.sleep(10)\n",
    "        html = driver.page_source\n",
    "        driver.quit()\n",
    "        tree = etree.HTML(html)\n",
    "        links = tree.xpath(\"//a[contains(@href, 'tag')]/@href\")\n",
    "        del(links[-1])\n",
    "        pattern = re.compile(r'(?<=tag/).*?(?=\\?)')\n",
    "        for link in links:\n",
    "            t_hash = re.findall(pattern, link)\n",
    "            hashes.extend(t_hash)\n",
    "        tag_hashes.extend(hashes)\n",
    "    tag_hashes = list(set(tag_hashes))\n",
    "    return tag_hashes\n",
    "\n",
    "# Generates params for api requests\n",
    "def generate_requests_dict(tag_hash, USER_ID, PASSCODE):\n",
    "    requests_dict = {\n",
    "    \"first_request\": {\n",
    "        \"tag_body\": {\n",
    "            \"bn\":\"broker3\",\n",
    "            \"userId\": USER_ID,\n",
    "            \"passCode\": PASSCODE, \n",
    "            \"client\":\"web\",\n",
    "            \"message\":{\n",
    "                \"key\": \"{}\".format(tag_hash), \n",
    "                \"th\": \"{}\".format(tag_hash), \n",
    "                \"t\": 2, \n",
    "                \"allowOffline\": True\n",
    "                        }},\n",
    "        \"api_url\" : \"https://restapi1.sharechat.com/requestType66\",\n",
    "        \"headers\": {\"content-type\": \"application/json\", \n",
    "                    \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36\"\n",
    "                   }}, \n",
    "    \"second_request\": {\n",
    "        \"tag_body\": {\n",
    "            \"bn\":\"broker3\",\n",
    "            \"userId\": USER_ID,\n",
    "            \"passCode\": PASSCODE, \n",
    "            \"client\":\"web\",\n",
    "            \"message\":{\n",
    "                \"th\": \"{}\".format(tag_hash), \n",
    "                \"allowOffline\": True}},\n",
    "        \"api_url\": \"https://restapi1.sharechat.com/getViralPostsSeo\",\n",
    "        \"headers\": {\"content-type\": \"application/json\", \n",
    "                    \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36\"\n",
    "                       }}}\n",
    "    return requests_dict\n",
    "\n",
    "def get_first_payload_data(payload_dict):\n",
    "    tag_name = payload_dict[\"payload\"][\"n\"]\n",
    "    tag_translation = payload_dict[\"payload\"][\"englishMeaning\"]\n",
    "    tag_genre = payload_dict[\"payload\"][\"tagGenre\"]\n",
    "    bucket_name = payload_dict[\"payload\"][\"bn\"]\n",
    "    bucket_id = payload_dict[\"payload\"][\"bi\"]\n",
    "    return tag_name, tag_translation, tag_genre, bucket_name, bucket_id\n",
    "\n",
    "\n",
    "def get_second_payload_data(payload_dict):\n",
    "    link = []\n",
    "    timestamp = []\n",
    "    language = []\n",
    "    media_type = []\n",
    "    for i in payload_dict[\"payload\"][\"d\"]:\n",
    "        if (i[\"t\"] == \"image\") | (i[\"t\"] == \"video\"):\n",
    "            timestamp.append(i[\"o\"])\n",
    "            language.append(i[\"m\"])\n",
    "            media_type.append(i[\"t\"])\n",
    "            if i[\"t\"] == \"image\":\n",
    "                link.append(i[\"g\"])\n",
    "            else:\n",
    "                link.append(i[\"v\"])\n",
    "        else:\n",
    "            pass # skip other content formats\n",
    "    return link, timestamp, language, media_type\n",
    "\n",
    "# Converts links to thumbnails in html\n",
    "def convert_links_to_thumbnails(df):   \n",
    "    def path_to_image_html(path):\n",
    "        return '<img src=\"'+ path + '\"width=\"200\" >' \n",
    "    image_df = df[df[\"media_type\"] == \"image\"]\n",
    "    pd.set_option('display.max_colwidth', -1)\n",
    "    data_html = HTML(image_df.to_html(escape=False ,formatters=dict(thumbnail=path_to_image_html))) \n",
    "    return data_html\n",
    "\n",
    "# Saves data in csv and html formats\n",
    "def save_data(df, html):\n",
    "    with open(\"sharechat_tag_data_preview.html\", \"w\") as f:\n",
    "        f.write(html.data)\n",
    "    df.drop(\"thumbnail\", axis = 1, inplace = True)\n",
    "    df.to_csv(\"sharechat_tag_data.csv\")\n",
    "\n",
    "# Get tag data\n",
    "def get_data(tag_hashes):\n",
    "    # Create empty dataframe to collect scraped data\n",
    "    df = pd.DataFrame(columns = [\"link\", \"timestamp\", \"language\", \n",
    "                                   \"media_type\", \"tag_name\", \"tag_translation\", \"tag_genre\", \"bucket_name\", \"bucket_id\", \"thumbnail\"])\n",
    "    print(\"Scraping data from Sharechat ...\")\n",
    "    for tag_hash in tag_hashes:\n",
    "        requests_dict = generate_requests_dict(tag_hash, USER_ID, PASSCODE)\n",
    "        # Send API request to check tag type\n",
    "        first_url = requests_dict[\"first_request\"][\"api_url\"]\n",
    "        first_body = requests_dict[\"first_request\"][\"tag_body\"]\n",
    "        first_headers = requests_dict[\"first_request\"][\"headers\"]\n",
    "        time.sleep(uniform(30,35)) # random time delay between requests\n",
    "        first_response = requests.post(url=first_url, json=first_body, headers=first_headers)\n",
    "        first_response_dict = json.loads(first_response.text)\n",
    "        if (first_response_dict[\"payload\"][\"bi\"] == 1284) or (first_response_dict[\"payload\"][\"tagCategory\"] == \"Temporary\"):\n",
    "            tag_name, tag_translation, tag_genre, bucket_name, bucket_id = get_first_payload_data(first_response_dict)\n",
    "            second_url = requests_dict[\"second_request\"][\"api_url\"]\n",
    "            second_body = requests_dict[\"second_request\"][\"tag_body\"]\n",
    "            second_headers = requests_dict[\"second_request\"][\"headers\"] \n",
    "            time.sleep(uniform(0.5,2))\n",
    "            second_response = requests.post(url=second_url, json=second_body, headers=second_headers)\n",
    "            second_response_dict = json.loads(second_response.text)\n",
    "            link, timestamp, language, media_type = get_second_payload_data(second_response_dict)\n",
    "            tag_data = pd.DataFrame(np.column_stack([link, timestamp, language, media_type]), \n",
    "                            columns = [\"link\", \"timestamp\", \"language\", \"media_type\"])\n",
    "            tag_data[\"tag_name\"] = tag_name\n",
    "            tag_data[\"tag_translation\"] = tag_translation\n",
    "            tag_data[\"tag_genre\"] = tag_genre\n",
    "            tag_data[\"bucket_name\"] = bucket_name\n",
    "            tag_data[\"bucket_id\"] = int(bucket_id)\n",
    "            tag_data[\"thumbnail\"] = tag_data[\"link\"]\n",
    "            df = df.append(tag_data)\n",
    "    df[\"timestamp\"] = df[\"timestamp\"].apply(lambda x: datetime.fromtimestamp(int(x), local_timezone).strftime(\"%d-%m-%Y, %H:%M:%S\"))\n",
    "    df.drop_duplicates(inplace = True)\n",
    "    return df\n",
    "\n",
    "    \n",
    "# Build scraper \n",
    "def sharechat_tag_scraper(buckets, destination):\n",
    "    start_time = time.time()\n",
    "    # Get tag hashes\n",
    "    tag_hashes = get_tag_hashes(buckets)\n",
    "    # Scrape data from each tag\n",
    "    sharechat_df = get_data(tag_hashes)\n",
    "    # Generate html file with image thumbnails\n",
    "    sharechat_data_html = convert_links_to_thumbnails(sharechat_df)\n",
    "    # Save data \n",
    "    save_data(sharechat_df, sharechat_data_html)\n",
    "    print(\"{} posts scraped\".format(len(sharechat_df)))\n",
    "    if len(sharechat_df) > 0:\n",
    "        print(\"Data saved to\", destination)\n",
    "    else:\n",
    "        print(\"No relevant data found!\")\n",
    "    print(\"Time taken: %s seconds\" % (time.time() - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run scraper\n",
    "sharechat_tag_scraper(buckets, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beautiful Soup scraper\n",
    "\n",
    "# Define scraper arguments\n",
    "t = [\"topic/news-hindi-125\", \"topic/whatsapp-hindi-238\", \"trending/Hindi\"] # tags to scrape\n",
    "d = os.getcwd() # download destination\n",
    "\n",
    "# Define helper functions for Beautiful Soup scraper\n",
    "\n",
    "# Scrapes data from specified tags\n",
    "def get_data(tags):\n",
    "    # Create empty dataframe to collect scraped data\n",
    "    data = pd.DataFrame(columns = [\"img_link\", \"timestamp\", \"tag\", \"thumbnail\"])\n",
    "    # Scrape data from each tag\n",
    "    for tag in tags: \n",
    "        print(\"Scraping recent images from https://sharechat.com/\"+tag+\" ...\")\n",
    "        soup = get_parsed_page(tag) \n",
    "        img_links, timestamps = get_images_with_timestamps(soup)  \n",
    "        # Save tag data as dataframe\n",
    "        tag_data = pd.DataFrame(np.column_stack([img_links, timestamps]), \n",
    "                            columns = [\"img_link\", \"timestamp\"])\n",
    "        # Add tag column \n",
    "        tag_data[\"tag\"] = tag\n",
    "        # Add thumbnail column\n",
    "        tag_data[\"thumbnail\"] = tag_data[\"img_link\"]   \n",
    "        # Add tag data \n",
    "        data = data.append(tag_data)\n",
    "    return data\n",
    "\n",
    "# Returns parsed web page\n",
    "def get_parsed_page(tag):\n",
    "    r = requests.get(\"https://sharechat.com/\"+tag)\n",
    "    c = r.content\n",
    "    soup = BeautifulSoup(c, \"lxml\") \n",
    "    return soup\n",
    "\n",
    "# Returns images with timestamps\n",
    "def get_images_with_timestamps(soup):\n",
    "    # Initialize empty lists to hold data\n",
    "    img_links = []\n",
    "    timestamps = []\n",
    "    # Find image\n",
    "    images = soup.findAll(\"img\", {\"src\": re.compile(\".jpg\")}) \n",
    "    for image in images:\n",
    "        # Add image link\n",
    "        img_links.append(image[\"src\"]) \n",
    "        # Find timestamp\n",
    "        unix_ts = re.findall(\"\\d{13}\", image[\"src\"]) \n",
    "        if (len(unix_ts) > 0): # If link contains timestamp\n",
    "        # Reformat and save timestamp\n",
    "            local_time = datetime.fromtimestamp(int(\"\".join(unix_ts))/1000, local_timezone).strftime(\"%d:%m:%Y, %H:%M:%S\")\n",
    "            timestamps.append(local_time) \n",
    "        else:\n",
    "            timestamps.append(None)\n",
    "    return img_links, timestamps\n",
    "\n",
    "# Adds image thumbnails for quick viewing\n",
    "def convert_links_to_thumbnails(df):   \n",
    "    def path_to_image_html(path):\n",
    "        return '<img src=\"'+ path + '\"width=\"200\" >' \n",
    "    data_html = HTML(df.to_html(escape=False ,formatters=dict(thumbnail=path_to_image_html))) \n",
    "    return data_html\n",
    "\n",
    "# Saves scraped data in csv and html formats\n",
    "def save_data(df, html):\n",
    "    with open(\"sharechat_data_html.html\", \"w\") as f:\n",
    "        f.write(html.data)\n",
    "    df.drop(\"thumbnail\", axis = 1, inplace = True)\n",
    "    df.to_csv(\"sharechat_data.csv\")\n",
    "    \n",
    "# Define Beautiful Soup scraper \n",
    "def sharechat_soup_scraper(tags, destination):\n",
    "    # Scrape data from specified tags\n",
    "    sharechat_df = get_data(tags)\n",
    "    # Generate html file with image thumbnails\n",
    "    sharechat_data_html = convert_links_to_thumbnails(sharechat_df)\n",
    "    # Save data \n",
    "    save_data(sharechat_df, sharechat_data_html)\n",
    "    print(\"{} images scraped\".format(len(sharechat_df)))\n",
    "    print(\"Data saved to\", destination)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Beautiful Soup scraper\n",
    "sharechat_soup_scraper(t, d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}